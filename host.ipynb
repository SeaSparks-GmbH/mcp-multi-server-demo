{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "70bcf545f064c8eb"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:07.081939Z",
     "start_time": "2025-04-16T16:56:07.078926Z"
    }
   },
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Start a Server",
   "id": "6d92675a482e686d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:08.561799Z",
     "start_time": "2025-04-16T16:56:08.559219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "# Global list to keep track of all subprocesses\n",
    "notebook_subprocesses = []"
   ],
   "id": "406924d06314ea6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:09.383695Z",
     "start_time": "2025-04-16T16:56:09.376589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Math Server (port 58000)\n",
    "proc = subprocess.Popen([\"python\", \"math_server.py\"])\n",
    "notebook_subprocesses.append(proc)"
   ],
   "id": "45f3b5975dbe0c5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Start another server",
   "id": "5c942391c85fd163"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:10.971075Z",
     "start_time": "2025-04-16T16:56:10.964648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Weather Server (port 58001)\n",
    "# Math Server (port 58000)\n",
    "proc = subprocess.Popen([\"python\", \"weather_server.py\"])\n",
    "notebook_subprocesses.append(proc)"
   ],
   "id": "16f912f8bd219458",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Client",
   "id": "cbe1d4e129125b00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:13.606544Z",
     "start_time": "2025-04-16T16:56:13.475071Z"
    }
   },
   "cell_type": "code",
   "source": "from client import MultiServerClient",
   "id": "511fb73b2ca9148d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The host",
   "id": "35a225050902d673"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:16.174304Z",
     "start_time": "2025-04-16T16:56:15.985838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "openai_key = \"your-api-key-here\"  # Replace with your key\n",
    "\n",
    "# Method to query the llm\n",
    "async def query_openai(prompt):\n",
    "    llm_client = AsyncOpenAI(api_key=oai_key)\n",
    "    return await llm_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "async def run_host_query(user_input: str):\n",
    "\n",
    "    endpoints = {\n",
    "        \"math_server\": \"http://127.0.0.1:58000/sse\",\n",
    "        \"weather_server\": \"http://127.0.0.1:58001/sse\"\n",
    "    }\n",
    "\n",
    "    # Initialize connections to all servers\n",
    "    mcp_client = MultiServerClient(endpoints)\n",
    "    print(\"Connect to servers...\")\n",
    "    await mcp_client.connect_all()\n",
    "\n",
    "    # Get all tools from all servers\n",
    "    tools_by_server = await mcp_client.list_all_tools()\n",
    "    tool_summary = []\n",
    "    for server, tools in tools_by_server.items():\n",
    "        for tool in tools:\n",
    "            tool_summary.append(f\"server: {server}, tool: {tool.name}, description: {tool.description} input schema: {tool.inputSchema}\")\n",
    "    print(\"Tool summaries:\", tool_summary)\n",
    "\n",
    "    # Define a simple prompt which tells the llm which tools are available and how to structure the response\n",
    "    prompt = f\"\"\"\n",
    "You are a tool routing assistant. Choose the best tool for the user query. Available tools:\n",
    "\n",
    "{chr(10).join(tool_summary)}\n",
    "\n",
    "Given the user query: \"{user_input}\"\n",
    "Respond only with a JSON object like:\n",
    "{{\"server\": \"math_server\", \"tool\": \"add\", \"args\": {{\"a\": 3, \"b\": 5}}}}\n",
    "\"\"\"\n",
    "\n",
    "    # Query the llm\n",
    "    response = await query_openai(prompt)\n",
    "\n",
    "    # Extract the llm response content\n",
    "    raw_content = response.choices[0].message.content\n",
    "\n",
    "    # Clean up markdown if present\n",
    "    cleaned_content = raw_content.strip().strip(\"```json\").strip(\"```\").strip()\n",
    "\n",
    "    # Parse JSON to see which tool was chosen\n",
    "    parsed = json.loads(cleaned_content)\n",
    "    print(\"LLM chose:\", parsed)\n",
    "\n",
    "    # Call the tool via the MCP client\n",
    "    result = await mcp_client.call(parsed[\"server\"], parsed[\"tool\"], parsed[\"args\"])\n",
    "    print(\"Tool result:\", result)\n",
    "\n",
    "    # Disconnect all\n",
    "    await mcp_client.disconnect_all()"
   ],
   "id": "f09d7fc8a02f4ed3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:20.642205Z",
     "start_time": "2025-04-16T16:56:18.332781Z"
    }
   },
   "cell_type": "code",
   "source": "await run_host_query(\"What's the weather like in Berlin?\")",
   "id": "645bebb8c89266f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect to servers...\n",
      "INFO:     127.0.0.1:63710 - \"GET /sse HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63711 - \"POST /messages/?session_id=5e988a8b1bb24c618ee1f2e37a924d57 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63711 - \"POST /messages/?session_id=5e988a8b1bb24c618ee1f2e37a924d57 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63712 - \"GET /sse HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63713 - \"POST /messages/?session_id=9d5917a8db54488faf18113070f240e2 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63713 - \"POST /messages/?session_id=9d5917a8db54488faf18113070f240e2 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63711 - \"POST /messages/?session_id=5e988a8b1bb24c618ee1f2e37a924d57 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63713 - \"POST /messages/?session_id=9d5917a8db54488faf18113070f240e2 HTTP/1.1\" 202 Accepted\n",
      "Tool summaries: [\"server: math_server, tool: add, description: Adds two integers input schema: {'type': 'object', 'required': ['a', 'b'], 'properties': {'a': {'type': 'integer', 'description': 'First number'}, 'b': {'type': 'integer', 'description': 'Second number'}}}\", \"server: math_server, tool: multiply, description: Multiplies two integers input schema: {'type': 'object', 'required': ['a', 'b'], 'properties': {'a': {'type': 'integer', 'description': 'First number'}, 'b': {'type': 'integer', 'description': 'Second number'}}}\", \"server: weather_server, tool: get_weather, description: Returns fake weather input schema: {'type': 'object', 'required': ['city'], 'properties': {'city': {'type': 'string', 'description': 'City to get the weather for'}}}\"]\n",
      "LLM chose: {'server': 'weather_server', 'tool': 'get_weather', 'args': {'city': 'Berlin'}}\n",
      "INFO:     127.0.0.1:63713 - \"POST /messages/?session_id=9d5917a8db54488faf18113070f240e2 HTTP/1.1\" 202 Accepted\n",
      "Tool result: meta=None content=[TextContent(type='text', text='The weather in Berlin is sunny and 25Â°C.', annotations=None)] isError=False\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:56:27.847286Z",
     "start_time": "2025-04-16T16:56:26.110899Z"
    }
   },
   "cell_type": "code",
   "source": "await run_host_query(\"How many hours do 5 days have?\")",
   "id": "bafdbe9fd1fad3c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connect to servers...\n",
      "INFO:     127.0.0.1:63715 - \"GET /sse HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63716 - \"POST /messages/?session_id=e3967945ba1c4940a7016d3aa1f248bf HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63716 - \"POST /messages/?session_id=e3967945ba1c4940a7016d3aa1f248bf HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63717 - \"GET /sse HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:63718 - \"POST /messages/?session_id=f50a129cb4bd4008ae1789d5aa8a1717 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63718 - \"POST /messages/?session_id=f50a129cb4bd4008ae1789d5aa8a1717 HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63716 - \"POST /messages/?session_id=e3967945ba1c4940a7016d3aa1f248bf HTTP/1.1\" 202 Accepted\n",
      "INFO:     127.0.0.1:63718 - \"POST /messages/?session_id=f50a129cb4bd4008ae1789d5aa8a1717 HTTP/1.1\" 202 Accepted\n",
      "Tool summaries: [\"server: math_server, tool: add, description: Adds two integers input schema: {'type': 'object', 'required': ['a', 'b'], 'properties': {'a': {'type': 'integer', 'description': 'First number'}, 'b': {'type': 'integer', 'description': 'Second number'}}}\", \"server: math_server, tool: multiply, description: Multiplies two integers input schema: {'type': 'object', 'required': ['a', 'b'], 'properties': {'a': {'type': 'integer', 'description': 'First number'}, 'b': {'type': 'integer', 'description': 'Second number'}}}\", \"server: weather_server, tool: get_weather, description: Returns fake weather input schema: {'type': 'object', 'required': ['city'], 'properties': {'city': {'type': 'string', 'description': 'City to get the weather for'}}}\"]\n",
      "LLM chose: {'server': 'math_server', 'tool': 'multiply', 'args': {'a': 5, 'b': 24}}\n",
      "INFO:     127.0.0.1:63716 - \"POST /messages/?session_id=e3967945ba1c4940a7016d3aa1f248bf HTTP/1.1\" 202 Accepted\n",
      "Tool result: meta=None content=[TextContent(type='text', text='120', annotations=None)] isError=False\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Stop Servers",
   "id": "6d4dacbd5c44dac4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T16:57:07.167171Z",
     "start_time": "2025-04-16T16:57:07.165310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for proc in notebook_subprocesses:\n",
    "    proc.terminate()  # or proc.kill() for force\n",
    "notebook_subprocesses.clear()"
   ],
   "id": "d4a5d3ccaf6c70b4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c8fab8cc6f4b3f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mcp_test] *",
   "language": "python",
   "name": "conda-env-mcp_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
